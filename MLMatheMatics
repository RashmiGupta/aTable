
P(a|s)=N(mu,sigma^2), $`\sum_{t=-inf}^inf P(a_t|s_t) = 1 `$

loss = -log P(a_t|s_t)R_t
Gradient descent update w' = w - \nabla loss
**The Cauchy-Schwarz Inequality**\
$$\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)$$

**The Cauchy-Schwarz Inequality**

```math
\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)
```


